{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52d78e18",
   "metadata": {},
   "source": [
    "<strong> Inferential Statistics :- </strong> \n",
    "    \n",
    "Inferential statistics allows one to summarize data and draw inferences and conclusions from that data. By using sample data, an individual can determine what a population may think or how it has been affected using inferential statistics.\n",
    "\n",
    "Descriptive statistics explain data (such as a chart or graph), whereas inferential statistics allows you to make predictions (\"inferences\") based on that data. Inferential statistics is used to generate generalisations about a population based on data from samples.\n",
    "    \n",
    "    For example, you could stand at a mall and poll 100 individuals to see if they liked the movie Avengers. You could construct a bar chart of yes or no replies (that would be descriptive statistics) or you could use your study (and inferential statistics) to reason that roughly 75-80 percent of the public (all shoppers in all malls) loved the movie Avengers.<br>\n",
    "    \n",
    "    Inferential statistics is divided into two categories:\n",
    "    \n",
    "    1) Parameter estimation:- This implies using a statistic from your sample data (for example, the sample mean) to make a statement about a population parameter (i.e. the population mean).\n",
    "    2) Hypothesis tests :- This is where sample data can be used to answer research questions. For example, you might be curious in the efficacy of a new cancer therapy. Or if breakfast improves children's academic performance.\n",
    "\n",
    "But before going into anything we should know about Distributions.\n",
    "\n",
    "### Probability Distributions :->\n",
    "A probability distribution tells you what the probability of an event happening is. Probability distributions can show simple events, like tossing a coin or picking a card. They can also show much more complex events, like the probability of a certain drug successfully treating cancer. \n",
    "\n",
    "    The term 'distribution' is used in descriptive as well as inferential statistics. In descriptive statistics it stands for the (absolute or relative) frequency of the values of a variable. A frequency distribution describes statistical data.\n",
    "\n",
    "    In inferential statistics, it describes the distribution of probability of individual values for different variables. Mathematically, this describes the distribution function and the density function.  \n",
    "\n",
    "A probability distribution is a statistical function that describes all possible values and probabilities for a random variable within a certain range. This range will be defined by the minimum and maximum possible values, but the location of the potential value on the probability distribution will be controlled by a variety of factors. Among these are the distribution's mean (average), standard deviation, skewness, and kurtosis.\n",
    "\n",
    "<strong> To read about different probability distributions chech out this website :- https://www.analyticsvidhya.com/blog/2021/07/probability-types-of-probability-distribution-functions/ </strong>\n",
    "\n",
    "Properties of Probability Distributions :->\n",
    "\n",
    "<b>1) Symmetric Distribution :-></b> A probability distribution is said to be symmetric if and only if there exist a value x such that \n",
    "\n",
    "$$\n",
    "    f(x-x_{0}) = f(x+x_{0})\n",
    "$$\n",
    "\n",
    "where f is the probability distribution function if the distribution is continuous or the probability mass function if the distribution is discrete and often <b>the mean, median, and mode all occur at the same point</b>. In graphical form, symmetrical distributions may appear as a normal distribution \n",
    "<br>\n",
    "<img src = \"images/LognormalandNormalDistribution.webp\" alt = \"symmetric distribution\"/>\n",
    "<br>\n",
    "\n",
    "<b>2) Skewness :-></b> It is the measure of asummetry of the probability distribution of a real valued random variable around its mean. Skewness can be expressed as a measure of how far a given distribution deviates from a normal distribution. <b>A normal distribution has a skew of Zero.</b>\n",
    "Skewness can be calculated by given formula:->\n",
    "$$\n",
    "    g  =  \\frac{\\sum\\limits _{i=1}^{n} (x_{i} - \\bar{x})^3}{(n-1)s^3}\n",
    "$$\n",
    "\n",
    "$\n",
    "\\text{Where:,  }\\\\\n",
    "\\\\\n",
    "x_{i} \\text{ – is the ith sample, }\\\\\n",
    "\\\\  \n",
    "\\bar{x}\\text{ – is the sample mean, } \\\\\n",
    "\\\\  \n",
    "s \\text{ – is the standard deviation, } \\\\\n",
    "\\\\  \n",
    "n \\text{ – is the total number of observations, } \\\\\n",
    "\\\\  \n",
    "g \\text{ - sample skewness, }\n",
    "$\n",
    "\n",
    "<b>Skewness can be negative, positive, zero and even undefined. </b>\n",
    "    \n",
    "    i) Negative Skew :-> The left tail is longer, and the mass of the distribution is concentrated on the right side of the figure. It is also known as left skew.\n",
    "    \n",
    "    ii) Positive Skew :-> The right tail is longer, and the mass of the distribution is concentrated on left side of the figure. It is also known as right skew.\n",
    "<br>   \n",
    "<img src= \"images/pearson-mode-skewness.jpeg\" alt = \"Left and Right skew\"/>\n",
    "<br>\n",
    "<br>\n",
    "<img src = \"images/skewness.png\" alt = \"B&W Left and Right skew\"/>\n",
    "<br>\n",
    "\n",
    "From the given figures we can see that, <b>Positively skewed data will have a higher mean than the median</b> on the other hand <b>negatively skewed data will have lower mean than the median.</b>\n",
    "\n",
    "<b>3) Kurtosis :-></b> It is the measure of tailedness of the probability distribution of real valued random variable. Basically it describes how much a distribution's tails diverge from the tails of a normal distribution. Whereas skewness differentiates extreme values in one versus the other tail, kurtosis measures extreme values in either tail. Kurtosis is calculated by given gormula :-\n",
    "\n",
    "$$\n",
    "\\mathrm{Kurt} =\\frac{\\mu_{4}}{\\sigma^{4}}\n",
    "$$\n",
    "\n",
    "$\n",
    "\\text{Where:,  }\\\\\n",
    "\\\\ \n",
    "\\mathrm{Kurt}\t=\t\\text{kurtosis, } \\\\\n",
    "\\\\\n",
    "\\mu_{4}\t= \\text{fourth central moment about mean, } \\\\\n",
    "\\\\\n",
    "\\sigma^{4}\t= \\text{standard deviation (second sample moment about mean), }\n",
    "\\\\\n",
    "$\n",
    "\n",
    "which is calculated as :-\n",
    "\n",
    "$$\n",
    "   Kurt =  \\frac{\\frac{\\sum(x-\\bar{x})^4}{n}}{\\frac{\\sum(x-\\bar{x})^2}{n}}\n",
    "$$\n",
    "\n",
    "\n",
    "<b> Kurtosis of normal random variable is 3. So excess kurtosis is calculated as kurtosis - 3</b>, we are measuring how different is the shape of distribution from the gaussian or normal distribution (whose kurtosis is 3).\n",
    "\n",
    "The sample kurtosis is useful measure of whether there is problem in outlier in dataset or not. Larger kurtosis indicates, a more serious outlier problem in the dataset, and may lead researchers to choose alternate statistical methods. \n",
    "\n",
    "    1) When Excess Kurtosis is Zero :- When excess kurtosis is zero that mean kurtosis of distribution is equal to 3, which is equal to normal distribution.\n",
    "    \n",
    "    2) When Excess Kurtosis is Negative :- Negative excess values of kurtosis (<3) indicate that a distribution is flat and has thin tails.\n",
    "    \n",
    "    3) When Excess Kurtosis is Positive :- Positive excess values of kurtosis (>3) indicate that a distribution is peaked and possess thick tails. Leptokurtic distributions have positive kurtosis values.\n",
    "<br>   \n",
    "<img src = \"images/Kurtosis1.jpeg\" alt = \"kurtosis example 1\"/>\n",
    "<br>\n",
    "<br>\n",
    "<img src = \"images/kurtosis2.png\" alt = \"kurtosis example 2\"/>\n",
    "\n",
    "<br>\n",
    "\n",
    "### Center Limit Theorem :-> \n",
    "Center Limit Theorem says that irrespective of sample/population distribution if we take samples and calculate their mean and plot then, <b>the means of sample taken from sample/population distribution is normally distributed.</b><br>\n",
    "Because we know that the sample means are normally distributed we dont need to worry too much about the distributions that the sample came from. We can use the mean's normal distribution to make confidence interval do t-tests, where we ask if there is a difference between two mean's from two samples, do ANNOVA test, where we ask if there is a difference among the means from three or more samples.\n",
    "\n",
    "<b> Note :- For CLT sample size should be greater than 30.</b>\n",
    "\n",
    "CLT says distribution of means will belong to normal distribution with mean equal to population mean and standard deviation of mean's would be equal to ratio of standard deviation of population to square root of sample size.\n",
    "\n",
    "\n",
    "$$\n",
    "\\mu_{\\bar{x}} = \\mu \\\\\n",
    "\\sigma_{x} = \\frac{\\sigma}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "$\n",
    "\\text{Where:,  }\\\\\n",
    "\\\\\n",
    "\\mu_{\\bar{x}} \\text{ – samples mean, }\\\\\n",
    "\\\\ \n",
    "\\mu \\text{ – mean of population, }\\\\\n",
    "\\\\ \n",
    "\\sigma_{x} \\text{ – samples standard deviation, }\\\\\n",
    "\\\\ \n",
    "\\sigma \\text{ – standard deviation of population, }\\\\\n",
    "\\\\ \n",
    "n \\text{ – sample size, }\n",
    "\\\\\n",
    "$\n",
    "\n",
    "\n",
    "### Standard Error and Standard Deviation :->\n",
    "<br>\n",
    "<img src = \"images/WhatsApp Image 2022-06-01 at 7.59.22 PM.jpeg\" alt = \"stndard error\" width =500 height =500/>\n",
    "<br>\n",
    "<img src = \"images/WhatsApp Image 2022-06-01 at 7.59.23 PM.jpeg\" alt = \"3 common error\" width =500 height =500/>\n",
    "<br>\n",
    "\n",
    "### Confidence Interval :-> \n",
    "The degree of uncertainty or certainty in a sampling process is measured by confidence intervals. A confidence interval is the mean of your estimate plus and minus the variation in that estimate. This is the range of values you expect your estimate to fall between if you redo your test, within a certain level of confidence.\n",
    "\n",
    "Best Site to learn about Confidence interval - https://www.mathsisfun.com/data/confidence-interval.html\n",
    "\n",
    "First read confidence interval from above site and then continue here. \n",
    "\n",
    "Confidence Interval can be calculated in 3 ways :-\n",
    "\n",
    "    1) If we know only Population dev :- we know that sample mean distribution belongs to Normal distribution. So our mean would be same as of Population mean and std will be (population std/root(n)).\n",
    "    \n",
    "$$\n",
    "    \\mu \\in [\\bar{x} - \\frac{2\\sigma}{\\sqrt{n}}  ,  \\bar{x} + \\frac{2\\sigma}{\\sqrt{n}} ]\n",
    "$$\n",
    "\n",
    "    as we know standard deviation we can simply put in the abouve equation and calculate confidence interval.\n",
    "    \n",
    "    2) If we dont know Poulation dev :- In this case we can use t-test or Z-test.\n",
    "    \n",
    "    3) We can use bootstrapping :- If we have a sample from a given population then, we can create m samples from given sample. Find out mean, median, mode of all samples, sort them and then find percentiles.\n",
    "    \n",
    "<img src = \"images/WhatsApp Image 2022-06-02 at 8.18.45 AM.jpeg\" alt = \"bootstraping method\" width =500 height =500/>\n",
    "\n",
    "### P-Value :->\n",
    "P value is the probability that <span style=\"color:blue\">random chance generated that data</span> <span style=\"color:green\">or something else that is equal to</span> <span style=\"color:red\">rarer</span>. So p value consist of 3 parts.\n",
    "\n",
    "Soppose we toss a coin 5 times then, p-value for 4 heads and 1 tail would be :\n",
    "\n",
    "    1) random chance generated that data --> probaility of getting 4 heads and 1 tail. (to get exactly 4 heads ={(HHHHT), (HHHTH), (HHTHH), (HTHHH), (THHHH) } so out of 32 chances 5 chances are favarable. so Probaility of first part is 5/32.\n",
    "    \n",
    "    2) something else that is equal to --> probability of getting 4 tails and 1 head. similarly its probabilty would be 5/32\n",
    "    \n",
    "    3) rarer --> probability of getting 5 heads and 0 tails, and probability of getting 5 tails and 0 heads. its probability would be (1/32) for getting all heads and (1/32) for getting all tails\n",
    "    \n",
    "    so p value would be (5/32 +5/32 + 1/32 +1/32) = 0.375\n",
    "    \n",
    "\n",
    "### Hypothesis Testing :->\n",
    "Hypothesis Testing is a type of statistical analysis in which we put your assumptions about a population parameter to the test. It is used to estimate the relationship between 2 statistical variables. It is most often used by scientists to test specific predictions, called hypotheses, that arise from theories. There are 5 main steps in hypothesis testing:\n",
    "\n",
    "    1) State your research hypothesis as a null hypothesis (Ho) and alternate hypothesis (Ha or H1).\n",
    "    \n",
    "    2) Collect data in a way designed to test the hypothesis.\n",
    "    \n",
    "    3) Perform an appropriate statistical test.\n",
    "    \n",
    "    4) Decide whether to reject or fail to reject your null hypothesis.\n",
    "    \n",
    "    5) Present the findings in your results and discussion section.\n",
    "    \n",
    "    Though the specific details might vary, the procedure you will use when testing a hypothesis will always follow some version of these steps.\n",
    "    \n",
    "<b>For Example, given a coin determine if the coin is baised towards head or not.</b>\n",
    "    \n",
    "    Experiment - Flip a coin 10 times. \n",
    "    So, our Null Hypothesis(H0) is coin is not baised. Then alternale Null Hypothesis(Ha) would be coin is baised towards head.\n",
    "    \n",
    "    In the p-value approach neither a significance level nor a critical value are determined before the experiment is carried out or the sample taken.  The null and alternative hypotheses are stated, and the experiment is run.  The determination of an outcome being more extreme than the observed outcome is based on the null and alternative hypotheses.\n",
    "\n",
    "    For now, lets come back to tossing experiment where the null hypothesis is that the coin is fair (p=0.5) and the alternative hypothesis is that the coin is biased in favor of heads (p>0.5).\n",
    "    \n",
    "    Suppose the coin is tossed 10 times and 8 heads are observed.  \n",
    "    \n",
    "    Since the alternative hypothesis is p>0.5, more extreme values are numbers of heads closer to 10.  \n",
    "    \n",
    "    So, to compute the p-value in this situation, we need only compute the probability of 8 or more heads in 10 tosses assuming the coin is fair.  But, the number of heads in 10 tosses of a coin assuming that the coin is fair has a binomial distribution with n=10 and p=0.5. \n",
    "    \n",
    "    The p-value is P[8 heads] + P[9 heads] + P[10 heads]. From the binomial probability distribution, P[8 heads]=0.044, P[9 heads]=0.01, and P[10 heads]=0.001.  Thus the p-value is 0.044+0.010+0.001=0.055.\n",
    "\n",
    "    Now that the p-value is computed, how do we decide whether to accept or reject the null hypothesis?  Since the p-value is simply the probability of getting the observed number of heads under the assumption that the null hypothesis is true, if this probability is small, it is unlikely that the null hypothesis is true.\n",
    "    \n",
    "    So 'small' p-values lead to rejection of the null hypothesis.  But 'small' is not defined.  The definition of small is up to the reader--if in the opinion of the reader, the p-value is small, the null hypothesis is rejected, while larger values would cause the null hypothesis to be accepted.  \n",
    "    \n",
    "    In statistical practice, 'small' values are usually 0.10, 0.05, or 0.01.  In the coin tosses above, the p-value is 0.055, and if a 'small' p-value for you is 0.05, you would fail to reject the null hypothesis, that is, you would say 8 heads in 10 tosses is not enough evidence to conclude that the coin is not fair.\n",
    "\n",
    "    The smaller the p-value, the stronger the evidence that you should reject the null hypothesis.\n",
    "\n",
    "    A p-value less than 0.05 (typically ≤ 0.05) is statistically significant. It indicates strong evidence against the null hypothesis, as there is less than a 5% probability the null is correct (and the results are random). Therefore, we reject the null hypothesis, and accept the alternative hypothesis.\n",
    "    \n",
    "    However, if the p-value is below your threshold of significance (typically p < 0.05), you can reject the null hypothesis, but this does not mean that there is a 95% probability that the alternative hypothesis is true. The p-value is conditional upon the null hypothesis being true, but is unrelated to the truth or falsity of the alternative hypothesis.\n",
    "\n",
    "    A p-value higher than 0.05 (> 0.05) is not statistically significant and indicates strong evidence for the null hypothesis. This means we retain the null hypothesis and reject the alternative hypothesis. You should note that you cannot accept the null hypothesis, we can only reject the null or fail to reject it. A statistically significant result cannot prove that a research hypothesis is correct (as this implies 100% certainty).\n",
    "\n",
    "\n",
    "### One Tail and Two Tail :->\n",
    "    \n",
    "    One Tail Test -> A one-tailed test is a statistical test in which the critical area of a distribution is one-sided so that it is either greater than or less than a certain value, but not both. If the sample being tested falls into the one-sided critical area, the alternative hypothesis will be accepted instead of the null hypothesis.\n",
    "    \n",
    "    Two Tail Test -> A two-tailed test, in statistics, is a method in which the critical area of a distribution is two-sided and tests whether a sample is greater than or less than a certain range of values. It is used in null-hypothesis testing and testing for statistical significance. If the sample being tested falls into either of the critical areas, the alternative hypothesis is accepted instead of the null hypothesis.\n",
    " <br>   \n",
    "<img src = \"images/one-tailed-vs-two-tailed-test.jpeg\" alt = \"one-tail-two-tail\"/>\n",
    "<br>\n",
    "<img src = \"images/Screenshot 2022-06-02 at 7.24.43 PM.png\" alt = \"one-tail-two-tail\" width = 700 height = 700/>\n",
    "<br>\n",
    "### Type 1 and Type 2 Error :->\n",
    "\n",
    "A hypothesis test can result in two types of errors.\n",
    "\n",
    "    Type 1 Error: A Type-I error occurs when sample results reject the null hypothesis despite being true.\n",
    "\n",
    "    Type 2 Error: A Type-II error occurs when the null hypothesis is not rejected when it is false, unlike a Type-I error.\n",
    "    \n",
    "Suppose a teacher evaluates the examination paper to decide whether a student passes or fails.\n",
    "\n",
    "H0: Student has passed\n",
    "\n",
    "H1: Student has failed\n",
    "\n",
    "Type I error will be the teacher failing the student [rejects H0] although the student scored the passing marks [H0 was true]. \n",
    "\n",
    "Type II error will be the case where the teacher passes the student [do not reject H0] although the student did not score the passing marks [H1 is true].\n",
    "\n",
    "<img src = \"images/type-1-and-2-errors.jpeg\" alt=\"type 1 and type 2 error\" width = 500 height = 500/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc14220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
